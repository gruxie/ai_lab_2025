# Lab 2.1 -Basic hypothesis generation 
In this exercise, you will use the attached prompts to generate assumptions and hypotheses based on data from previous steps (Labs 1.1 - 1.3, which focused on ramping up in a new domain). This is a Chain of Thought prompt that begins by forming a list of assumptions derived from the literature review in Lab 1.3. These assumptions are then used to construct hypotheses following the patterns from the hypotheses progression framework. The outcome will be a list of hypotheses along with recommendations for testing them.  



## Exercise 1: Generating assumptions and generating hypotheses 
> [!IMPORTANT]  
> This prompt requires continuity from the previous lab (literature review) for its context. Before running this prompt, ensure you have completed the previous step in Lab 1.3 (including the prompt and attached documents).  [Here's a link to Lab 1.3](../1.3_anno_lit_review/)

In this step, you will refine the **research question** from the previous lab (learning about information scent concepts). The research question in the prompt for Lab 2.1 is reframed as a product research question, applying this learning to a specific problem - the TangoDjango design. This is an important step in adapting to the next phase of hypothesis generation. This shift makes the hypotheses informed by your previous research but relevant to the project you are working on.  
1.  Run Exercise 1 from Lab [1.3]((../1.3_anno_lit_review/)) if you haven't already.
2.  Open and review the hypothesis generation prompt. It's configured for the "information scent" problem.
3.  Run the hypothesis generation prompt Phase 1 (assumptions generation).
4.  Review the output and ask any follow-up questions. Then type "next" to run Phase 2.   
  
## Exercise 2: Adding Critical Thinking Dialogue (Tough Love and Dialogue)
There is [growing research](https://www.microsoft.com/en-us/research/wp-content/uploads/2022/06/Aether-Overreliance-on-AI-Review-Final-6.21.22.pdf) about the hazards of overreliance on AI and its effects on cognitive abilities and poor results. One mitigation is to instruct the LLM to aid in reflection on the output and/or other metacognitive exercises to better challenge assumptions (see link pg. 7) and refine the output. This exercise introduces a follow-up prompt to the one proposed in Lab 2.1 that updates the LLM's instructions to help the user be more critical in their analysis (Socratic method). It works best after having read the documents you want to focus on. It works even better as a dialogue (multi-turn questions) and even better with ChatGPT's voice chat.
1.  Complete Exercise 1 from this lab (generating hypotheses).
2.  Run the 2.1b prompt [prompt link](../) to get started - it should start asking you questions!
3.  Respond to questions and keep the conversation going.
4.  When you want to quit and finalize the output, type "wrap up."

**Materials for this lab**  
- Domain:  Information scent and how it is used to navigate websites and software menu
- RQ for lit review (last lab):  What changes do we need to make to our website to make it easier to find the articles customers need?
- RQ: for hypothesis gen (this lab)    
	  
**Articles used for analysis (used in 1.3)**
Using Information Scent to Model User Information Needs and Actions on the Web
News Cues: Information Scent and Cognitive Heuristics
The Effect of Information Scent on Searching Information  Visualizations of Large Tree Structures 

Prompts
	• Prompt:  2.1a - Assumptions and hypotheses
	• Prompt:  2.1b - Socrates has entered the chat

Recommendations
	• Run the prompt more than once
	• Dialogue (multi turn conversation) is better than treating it like a search engine.

Worked example
Lab 2.1 - Basic hypothesis generation
